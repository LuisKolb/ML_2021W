{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e53893e-fe12-4815-a066-0bc97a2794eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Machine Learning Exercise 2 - Regression and AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7cfdffe-49f1-4960-a8cf-c03476cdb40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "import warnings\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', 999)\n",
    "\n",
    "def supress_warnings(suppress):\n",
    "    if suppress:\n",
    "        warnings.filterwarnings('ignore') # hide all warnings\n",
    "    else:\n",
    "        warnings.filterwarnings('default') # default warnings settings\n",
    "\n",
    "_print_hill_step = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f204ac40-cf6d-4fdc-aaed-27fadcf9430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_lower(val, list):\n",
    "    \"\"\"\n",
    "    returns False if there is an element in list greater val, True otherwise (including list=[])\n",
    "    \"\"\"\n",
    "    return(all(x < val for x in list))\n",
    "\n",
    "def fit_elastic(params, X_train, y_train):\n",
    "    elastic_model = ElasticNet(**params)\n",
    "    elastic_model.fit(X_train, y_train)\n",
    "    return elastic_model\n",
    "\n",
    "def fit_tree(params, X_train, y_train):\n",
    "    tree_model = DecisionTreeRegressor(**params)\n",
    "    tree_model.fit(X_train, y_train)\n",
    "    return tree_model\n",
    "\n",
    "def fit_mlp(params, X_train, y_train):\n",
    "    mlp_model = MLPRegressor(**params)\n",
    "    mlp_model.fit(X_train, y_train)\n",
    "    return mlp_model\n",
    "\n",
    "def build_generic(fit_fun, params, X_train, X_test, y_train, y_test):\n",
    "    timing = None\n",
    "    score = None\n",
    "\n",
    "    start = time.time()\n",
    "    model = eval(f'{fit_fun}(params, X_train, y_train.values.ravel())')\n",
    "    timing = time.time() - start\n",
    "            \n",
    "    r2 = model.score(X_test, y_test.values.ravel())\n",
    "    \n",
    "    return timing, r2\n",
    "\n",
    "def build_generic_with_cv(fit_fun, params, X, y, print_cv_res=False):\n",
    "    timing = None\n",
    "    score = None\n",
    "\n",
    "    start = time.time()\n",
    "    model = eval(f'{fit_fun}(params, X, y.values.ravel())')\n",
    "    timing = time.time() - start\n",
    "    \n",
    "    cv_res = cross_val_score(model, X, y.values.ravel(), cv=5, scoring='r2')\n",
    "    r2 = cv_res.mean()\n",
    "    \n",
    "    if print_cv_res:\n",
    "        print(cv_res)\n",
    "    \n",
    "    return timing, r2\n",
    "\n",
    "\n",
    "def step(stepped_params, params_dict, active_param, previous_params):\n",
    "    \"\"\"\n",
    "    Step the stepped_params according to the params_dict, which is formatted like {'param_name': [start, stop, step_size], ...} (e.g. [1,20,1])\n",
    "    \n",
    "    step_size can be negative, in this case start should be greater than stop (e.g. [20,1,-1])\n",
    "    \"\"\"  \n",
    "        \n",
    "    if not active_param:\n",
    "        # new param has to be chosen at random from ones not used yet\n",
    "        \n",
    "        if not previous_params:\n",
    "            # choose the first parameter to start stepping\n",
    "            active_param = random.choice(list(stepped_params.keys()))\n",
    "        else:\n",
    "            for p in  stepped_params:\n",
    "                if p in previous_params:\n",
    "                    # found a yet unused param\n",
    "                    continue\n",
    "                active_param = p\n",
    "\n",
    "    if not active_param:\n",
    "        # no param was left to choose, reset previous and active params to start again\n",
    "        return stepped_params, params_dict, None, []\n",
    "   \n",
    "    else:\n",
    "        mult = random.sample([1,1,1,1,2], k=1)\n",
    "        step_size = params_dict[active_param][2]\n",
    "        step_size = step_size*2\n",
    "        if math.copysign(1, step_size) < 0:\n",
    "            # descending step\n",
    "            if (stepped_params[active_param] + step_size) <= params_dict[active_param][1]:\n",
    "                stepped_params[active_param] = params_dict[active_param][1]\n",
    "                previous_params.append(active_param)\n",
    "                active_param = None\n",
    "            else:\n",
    "                stepped_params[active_param] = stepped_params[active_param] + step_size\n",
    "        else:\n",
    "            # ascending step\n",
    "            if (stepped_params[active_param] + step_size) >= params_dict[active_param][1]:\n",
    "                stepped_params[active_param] = params_dict[active_param][1]\n",
    "                previous_params.append(active_param)\n",
    "                active_param = None\n",
    "            else:\n",
    "                stepped_params[active_param] = stepped_params[active_param] + step_size\n",
    "    \n",
    "        \n",
    "        return stepped_params, params_dict, active_param, previous_params\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def climb_generic(n_iter, fit_fun, params_dict, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Generic function to hillclimb tune *one* algorithm's parameters for *one* dataset\n",
    "    \n",
    "    fit_fun should be in (fit_elastic, fit_tree, fit_mlp)\n",
    "    params_dict is a dict formatted like {'param_name': [start, stop, step_size], ...} (e.g. [1,20,1]), also works for negative descent which needs a negative step_size\n",
    "    \"\"\"\n",
    "    # get starting values\n",
    "    res = {}\n",
    "    curr_params = {}\n",
    "    active_param = ''\n",
    "    previous_params = []\n",
    "    \n",
    "    for p in params_dict:\n",
    "        curr_params[p] = params_dict[p][0]\n",
    "    \n",
    "    ret_timing, score = build_generic(fit_fun, curr_params, X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        stepped_params, params_dict, active_param, previous_params = step(curr_params, params_dict, active_param, previous_params)\n",
    "        ret_timing, ret_score = build_generic(fit_fun, stepped_params, X_train, X_test, y_train, y_test)\n",
    "        \n",
    "        if ret_score > score:\n",
    "            curr_params, score = stepped_params, ret_score\n",
    "            for p in curr_params:\n",
    "                res[p] = curr_params[p]\n",
    "            if _print_hill_step:\n",
    "                print((f'iter {i} {res}: {score}'))\n",
    "        else:\n",
    "            previous_params.append(active_param)\n",
    "            active_param = None\n",
    "            \n",
    "    \n",
    "    return res, score\n",
    "\n",
    "def climb_generic_with_cv(n_iter, fit_fun, params_dict, X, y, print_cv_res=False):\n",
    "    \"\"\"\n",
    "    Generic function to hillclimb tune *one* algorithm's parameters for *one* dataset, using 5-fold cross validation with stratified splitting\n",
    "    \n",
    "    fit_fun should be in (fit_elastic, fit_tree, fit_mlp)\n",
    "    params_dict is a dict formatted like {'param_name': [start, stop, step_size], ...} (e.g. [1,20,1]), also works for negative descent which needs a negative step_size\n",
    "    \"\"\"\n",
    "    \n",
    "    return climb_generic(n_iter, fit_fun, params_dict, X, y, print_cv_res)\n",
    "    # get starting values\n",
    "    res = {}\n",
    "    curr_params = {}\n",
    "    active_param = ''\n",
    "    previous_params = []\n",
    "    \n",
    "    for p in params_dict:\n",
    "        curr_params[p] = params_dict[p][0]\n",
    "    \n",
    "    ret_timing, score = build_generic_with_cv(fit_fun, curr_params, X_train, X_test, y_train, y_test, print_cv_res)\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        stepped_params, params_dict, active_param, previous_params = step(curr_params, params_dict, active_param, previous_params)\n",
    "        ret_timing, ret_score = build_generic_with_cv(fit_fun, stepped_params, X_train, X_test, y_train, y_test, print_cv_res)\n",
    "        \n",
    "        if ret_score > score:\n",
    "            curr_params, score = stepped_params, ret_score\n",
    "            for p in curr_params:\n",
    "                res[p] = curr_params[p]\n",
    "            if _print_hill_step:\n",
    "                print((f'iter {i} {res}: {score}'))\n",
    "        else:\n",
    "            previous_params.append(active_param)\n",
    "            active_param = None\n",
    "            \n",
    "    \n",
    "    return res, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7b56683-471b-4faf-80a8-229ab7b9f344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_ml(n_iter, alg_list, X, y):\n",
    "    r2_to_beat = 0\n",
    "    results = []\n",
    "    winner = None\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    \n",
    "    for alg, params_alg in alg_list:\n",
    "        print(f'>>>>> tuning {alg} with params {params_alg} <<<<<')\n",
    "        \n",
    "        res_params, score = climb_generic(n_iter, alg, params_alg, X_train, X_test, y_train, y_test)\n",
    "        print(f'{alg} {res_params}: {score}')\n",
    "            \n",
    "        res_dict = {\n",
    "            'alg': alg,\n",
    "            'res_params': res_params,\n",
    "            'score': score,\n",
    "        }\n",
    "        results.append(res_dict)\n",
    "        \n",
    "        if score > r2_to_beat:\n",
    "            winner = res_dict\n",
    "        \n",
    "    return winner, results\n",
    "\n",
    "def auto_ml_with_cv(n_iter, alg_list, X, y):\n",
    "    r2_to_beat = 0\n",
    "    results = []\n",
    "    winner = None\n",
    "    \n",
    "    for alg, params_alg in alg_list:\n",
    "        print(f'>>>>> tuning {alg} with params {params_alg} <<<<<')\n",
    "        \n",
    "        res_params, score = climb_generic_with_cv(n_iter, alg, params_alg, X, y)\n",
    "        print(f'{alg} {res_params}: {score}')\n",
    "            \n",
    "        res_dict = {\n",
    "            'alg': alg,\n",
    "            'res_params': res_params,\n",
    "            'score': score,\n",
    "        }\n",
    "        results.append(res_dict)\n",
    "        \n",
    "        if score > r2_to_beat:\n",
    "            winner = res_dict\n",
    "        \n",
    "    return winner, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5240dcd4-0f82-46fc-b6be-f57105a356f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "parameter spaces to search\n",
    "\"\"\"\n",
    "\n",
    "params_elastic = {\n",
    "    'alpha': [0.1, 10, 0.1],\n",
    "    'l1_ratio': [0,1,0.1],\n",
    "    'max_iter': [1000,100000,1000],\n",
    "}\n",
    "\n",
    "params_tree = {\n",
    "    'max_depth': [4,32,4],\n",
    "    'min_samples_split': [2,32,2],\n",
    "    'min_samples_leaf': [4,64,4],\n",
    "}\n",
    "\n",
    "params_mlp = {\n",
    "    'alpha': [0.001,0.01,0.001],\n",
    "    'n_iter_no_change': [16,8,-1],\n",
    "    'max_iter': [100,400,20]\n",
    "}\n",
    "\n",
    "alg_list = []\n",
    "alg_list.append(['fit_elastic', params_elastic])\n",
    "alg_list.append(['fit_tree', params_tree])\n",
    "alg_list.append(['fit_mlp', params_mlp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c822f59e-f507-4536-a238-de4f4d541f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "supress_warnings(True)\n",
    "_print_hill_step = False\n",
    "notebook_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10841dca-71dd-489e-827b-0fab7b8b9f6d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Breast Cancer Data\n",
    "\n",
    "https://www.kaggle.com/c/184702-tu-ml-ws-21-breast-cancer/data#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e233e6a5-f4fd-4007-9fea-51cdcf413537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>24</td>\n",
       "      <td>67</td>\n",
       "      <td>216</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>94</td>\n",
       "      <td>121</td>\n",
       "      <td>97</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>180</td>\n",
       "      <td>59</td>\n",
       "      <td>119</td>\n",
       "      <td>151</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>260</td>\n",
       "      <td>283</td>\n",
       "      <td>6</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>222</td>\n",
       "      <td>278</td>\n",
       "      <td>169</td>\n",
       "      <td>284</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>1</td>\n",
       "      <td>280</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>181</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>1</td>\n",
       "      <td>210</td>\n",
       "      <td>217</td>\n",
       "      <td>37</td>\n",
       "      <td>78</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>48</td>\n",
       "      <td>100</td>\n",
       "      <td>224</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>1</td>\n",
       "      <td>238</td>\n",
       "      <td>19</td>\n",
       "      <td>153</td>\n",
       "      <td>193</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>131</td>\n",
       "      <td>216</td>\n",
       "      <td>265</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>285 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target    0    1    2    3    4\n",
       "0         0  115   24   67  216   99\n",
       "1         0   57   94  121   97   51\n",
       "2         1  180   59  119  151  192\n",
       "3         0   29  260  283    6  279\n",
       "4         0  222  278  169  284    6\n",
       "..      ...  ...  ...  ...  ...  ...\n",
       "280       1  280    8    6  181  222\n",
       "281       1  210  217   37   78  215\n",
       "282       0   56   48  100  224   58\n",
       "283       1  238   19  153  193  139\n",
       "284       0  141  131  216  265   38\n",
       "\n",
       "[285 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>> tuning fit_elastic with params {'alpha': [0.1, 10, 0.1], 'l1_ratio': [0, 1, 0.1], 'max_iter': [1000, 100000, 1000]} <<<<<\n",
      "fit_elastic {'alpha': 10, 'l1_ratio': 0, 'max_iter': 1000}: 0.6448203193863158\n",
      ">>>>> tuning fit_tree with params {'max_depth': [4, 32, 4], 'min_samples_split': [2, 32, 2], 'min_samples_leaf': [4, 64, 4]} <<<<<\n",
      "fit_tree {}: 0.7488779064311066\n",
      ">>>>> tuning fit_mlp with params {'alpha': [0.001, 0.01, 0.001], 'n_iter_no_change': [16, 8, -1], 'max_iter': [100, 400, 20]} <<<<<\n",
      "fit_mlp {'alpha': 0.01, 'n_iter_no_change': 8, 'max_iter': 400}: -3.9285244961599313\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'alg': 'fit_tree', 'res_params': {}, 'score': 0.7488779064311066},\n",
       " [{'alg': 'fit_elastic',\n",
       "   'res_params': {'alpha': 10, 'l1_ratio': 0, 'max_iter': 1000},\n",
       "   'score': 0.6448203193863158},\n",
       "  {'alg': 'fit_tree', 'res_params': {}, 'score': 0.7488779064311066},\n",
       "  {'alg': 'fit_mlp',\n",
       "   'res_params': {'alpha': 0.01, 'n_iter_no_change': 8, 'max_iter': 400},\n",
       "   'score': -3.9285244961599313}])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breastcancer = pd.read_csv('preprocessed_data/breast-cancer-diagnostic.shuf.lrn_processed.csv', index_col=0)\n",
    "\n",
    "breastcancer = breastcancer.apply(LabelEncoder().fit_transform)\n",
    "display(breastcancer)\n",
    "\n",
    "breastcancer_X = breastcancer.drop('target', axis=1)\n",
    "breastcancer_y = breastcancer['target']\n",
    "\n",
    "auto_ml(100, alg_list, breastcancer_X, breastcancer_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad56e36-a5fb-4d01-a79f-2dbd6b97836f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Concrete Data  \n",
    "\n",
    "https://www.kaggle.com/prathamtripathi/regression-with-neural-networking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a54aa9fb-b01d-4cc7-9643-8aa583bd7e45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Strength</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79.99</td>\n",
       "      <td>0.214751</td>\n",
       "      <td>-0.396354</td>\n",
       "      <td>1.179814</td>\n",
       "      <td>0.125379</td>\n",
       "      <td>1.791528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61.89</td>\n",
       "      <td>0.217092</td>\n",
       "      <td>-0.405260</td>\n",
       "      <td>1.316810</td>\n",
       "      <td>0.112153</td>\n",
       "      <td>1.772801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.27</td>\n",
       "      <td>5.606084</td>\n",
       "      <td>-0.435139</td>\n",
       "      <td>-0.407134</td>\n",
       "      <td>0.606248</td>\n",
       "      <td>0.280933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41.05</td>\n",
       "      <td>7.384075</td>\n",
       "      <td>0.295037</td>\n",
       "      <td>-0.399784</td>\n",
       "      <td>0.442201</td>\n",
       "      <td>0.292490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.30</td>\n",
       "      <td>6.291732</td>\n",
       "      <td>2.459109</td>\n",
       "      <td>-0.156774</td>\n",
       "      <td>-0.423362</td>\n",
       "      <td>-0.869309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>44.28</td>\n",
       "      <td>-0.021691</td>\n",
       "      <td>0.374138</td>\n",
       "      <td>-0.863457</td>\n",
       "      <td>1.032798</td>\n",
       "      <td>0.113360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>31.18</td>\n",
       "      <td>-0.071329</td>\n",
       "      <td>0.483104</td>\n",
       "      <td>-1.429798</td>\n",
       "      <td>0.329372</td>\n",
       "      <td>0.130083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>23.70</td>\n",
       "      <td>0.080248</td>\n",
       "      <td>0.148299</td>\n",
       "      <td>-0.785831</td>\n",
       "      <td>1.135922</td>\n",
       "      <td>-0.881579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>32.77</td>\n",
       "      <td>-0.127364</td>\n",
       "      <td>0.365954</td>\n",
       "      <td>-0.014275</td>\n",
       "      <td>0.949949</td>\n",
       "      <td>-0.477926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>32.40</td>\n",
       "      <td>0.182111</td>\n",
       "      <td>-0.134997</td>\n",
       "      <td>-1.095062</td>\n",
       "      <td>0.830994</td>\n",
       "      <td>-0.157003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1030 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Strength         0         1         2         3         4\n",
       "0        79.99  0.214751 -0.396354  1.179814  0.125379  1.791528\n",
       "1        61.89  0.217092 -0.405260  1.316810  0.112153  1.772801\n",
       "2        40.27  5.606084 -0.435139 -0.407134  0.606248  0.280933\n",
       "3        41.05  7.384075  0.295037 -0.399784  0.442201  0.292490\n",
       "4        44.30  6.291732  2.459109 -0.156774 -0.423362 -0.869309\n",
       "...        ...       ...       ...       ...       ...       ...\n",
       "1025     44.28 -0.021691  0.374138 -0.863457  1.032798  0.113360\n",
       "1026     31.18 -0.071329  0.483104 -1.429798  0.329372  0.130083\n",
       "1027     23.70  0.080248  0.148299 -0.785831  1.135922 -0.881579\n",
       "1028     32.77 -0.127364  0.365954 -0.014275  0.949949 -0.477926\n",
       "1029     32.40  0.182111 -0.134997 -1.095062  0.830994 -0.157003\n",
       "\n",
       "[1030 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>> tuning fit_elastic with params {'alpha': [0.1, 10, 0.1], 'l1_ratio': [0, 1, 0.1], 'max_iter': [1000, 100000, 1000]} <<<<<\n",
      "fit_elastic {'alpha': 0.1, 'l1_ratio': 0, 'max_iter': 3000}: 0.5084868095956344\n",
      ">>>>> tuning fit_tree with params {'max_depth': [4, 32, 4], 'min_samples_split': [2, 32, 2], 'min_samples_leaf': [4, 64, 4]} <<<<<\n",
      "fit_tree {'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 12}: 0.6404796395063501\n",
      ">>>>> tuning fit_mlp with params {'alpha': [0.001, 0.01, 0.001], 'n_iter_no_change': [16, 8, -1], 'max_iter': [100, 400, 20]} <<<<<\n",
      "fit_mlp {'alpha': 0.01, 'n_iter_no_change': 8, 'max_iter': 400}: 0.7167436605393384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alg': 'fit_mlp',\n",
       " 'res_params': {'alpha': 0.01, 'n_iter_no_change': 8, 'max_iter': 400},\n",
       " 'score': 0.7167436605393384}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete = pd.read_csv('preprocessed_data/concrete_data_processed.csv', index_col=0)\n",
    "display(concrete)\n",
    "\n",
    "# preprocessing...\n",
    "\n",
    "concrete_X = concrete.drop('Strength', axis=1)\n",
    "concrete_y = pd.DataFrame(concrete['Strength'])\n",
    "\n",
    "concrete_winner, concrete_results = auto_ml(100, alg_list, concrete_X, concrete_y)\n",
    "concrete_winner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016cf9dd-204b-49f9-8a7d-ace1392223e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Seoul Bike Data  \n",
    "\n",
    "https://archive-beta.ics.uci.edu/ml/datasets/seoul+bike+sharing+demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e008f587-58d7-40e9-8069-d937535f529c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rented Bike Count</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>254</td>\n",
       "      <td>-1.143428</td>\n",
       "      <td>1.720607</td>\n",
       "      <td>0.576782</td>\n",
       "      <td>0.171896</td>\n",
       "      <td>-0.362174</td>\n",
       "      <td>-0.509898</td>\n",
       "      <td>1.001663</td>\n",
       "      <td>-0.057253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>204</td>\n",
       "      <td>-0.932272</td>\n",
       "      <td>1.855252</td>\n",
       "      <td>0.185010</td>\n",
       "      <td>0.350632</td>\n",
       "      <td>-0.943400</td>\n",
       "      <td>-0.811276</td>\n",
       "      <td>0.434694</td>\n",
       "      <td>-0.070336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>173</td>\n",
       "      <td>-0.963323</td>\n",
       "      <td>1.843890</td>\n",
       "      <td>0.251450</td>\n",
       "      <td>0.322785</td>\n",
       "      <td>-0.806922</td>\n",
       "      <td>-0.760837</td>\n",
       "      <td>0.440454</td>\n",
       "      <td>-0.052111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107</td>\n",
       "      <td>-0.943335</td>\n",
       "      <td>1.849751</td>\n",
       "      <td>0.227829</td>\n",
       "      <td>0.331231</td>\n",
       "      <td>-0.802215</td>\n",
       "      <td>-0.779956</td>\n",
       "      <td>0.339291</td>\n",
       "      <td>-0.040505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78</td>\n",
       "      <td>-1.215630</td>\n",
       "      <td>1.710387</td>\n",
       "      <td>0.688144</td>\n",
       "      <td>0.203102</td>\n",
       "      <td>-0.143203</td>\n",
       "      <td>-0.506954</td>\n",
       "      <td>0.759400</td>\n",
       "      <td>-0.028478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8755</th>\n",
       "      <td>1003</td>\n",
       "      <td>-0.599769</td>\n",
       "      <td>0.239326</td>\n",
       "      <td>0.233114</td>\n",
       "      <td>1.551041</td>\n",
       "      <td>0.900681</td>\n",
       "      <td>0.632778</td>\n",
       "      <td>-0.111454</td>\n",
       "      <td>-0.099430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8756</th>\n",
       "      <td>764</td>\n",
       "      <td>-0.546395</td>\n",
       "      <td>0.269275</td>\n",
       "      <td>0.142696</td>\n",
       "      <td>1.615954</td>\n",
       "      <td>0.829516</td>\n",
       "      <td>0.544198</td>\n",
       "      <td>-0.251335</td>\n",
       "      <td>-0.094189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8757</th>\n",
       "      <td>694</td>\n",
       "      <td>-0.234729</td>\n",
       "      <td>0.479374</td>\n",
       "      <td>-0.427990</td>\n",
       "      <td>1.848822</td>\n",
       "      <td>-0.024300</td>\n",
       "      <td>0.137934</td>\n",
       "      <td>-1.038696</td>\n",
       "      <td>-0.107280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8758</th>\n",
       "      <td>712</td>\n",
       "      <td>-0.308480</td>\n",
       "      <td>0.428752</td>\n",
       "      <td>-0.239147</td>\n",
       "      <td>1.691474</td>\n",
       "      <td>0.331681</td>\n",
       "      <td>0.350278</td>\n",
       "      <td>-0.878422</td>\n",
       "      <td>-0.058397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8759</th>\n",
       "      <td>584</td>\n",
       "      <td>-0.338726</td>\n",
       "      <td>0.386661</td>\n",
       "      <td>-0.159333</td>\n",
       "      <td>1.658494</td>\n",
       "      <td>0.526559</td>\n",
       "      <td>0.402532</td>\n",
       "      <td>-0.820014</td>\n",
       "      <td>-0.040774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8760 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Rented Bike Count         0         1         2         3         4  \\\n",
       "0                   254 -1.143428  1.720607  0.576782  0.171896 -0.362174   \n",
       "1                   204 -0.932272  1.855252  0.185010  0.350632 -0.943400   \n",
       "2                   173 -0.963323  1.843890  0.251450  0.322785 -0.806922   \n",
       "3                   107 -0.943335  1.849751  0.227829  0.331231 -0.802215   \n",
       "4                    78 -1.215630  1.710387  0.688144  0.203102 -0.143203   \n",
       "...                 ...       ...       ...       ...       ...       ...   \n",
       "8755               1003 -0.599769  0.239326  0.233114  1.551041  0.900681   \n",
       "8756                764 -0.546395  0.269275  0.142696  1.615954  0.829516   \n",
       "8757                694 -0.234729  0.479374 -0.427990  1.848822 -0.024300   \n",
       "8758                712 -0.308480  0.428752 -0.239147  1.691474  0.331681   \n",
       "8759                584 -0.338726  0.386661 -0.159333  1.658494  0.526559   \n",
       "\n",
       "             5         6         7  \n",
       "0    -0.509898  1.001663 -0.057253  \n",
       "1    -0.811276  0.434694 -0.070336  \n",
       "2    -0.760837  0.440454 -0.052111  \n",
       "3    -0.779956  0.339291 -0.040505  \n",
       "4    -0.506954  0.759400 -0.028478  \n",
       "...        ...       ...       ...  \n",
       "8755  0.632778 -0.111454 -0.099430  \n",
       "8756  0.544198 -0.251335 -0.094189  \n",
       "8757  0.137934 -1.038696 -0.107280  \n",
       "8758  0.350278 -0.878422 -0.058397  \n",
       "8759  0.402532 -0.820014 -0.040774  \n",
       "\n",
       "[8760 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>> tuning fit_elastic with params {'alpha': [0.1, 10, 0.1], 'l1_ratio': [0, 1, 0.1], 'max_iter': [1000, 100000, 1000]} <<<<<\n",
      "fit_elastic {'alpha': 0.30000000000000004, 'l1_ratio': 1, 'max_iter': 3000}: 0.4696670117932351\n",
      ">>>>> tuning fit_tree with params {'max_depth': [4, 32, 4], 'min_samples_split': [2, 32, 2], 'min_samples_leaf': [4, 64, 4]} <<<<<\n",
      "fit_tree {'max_depth': 28, 'min_samples_split': 6, 'min_samples_leaf': 28}: 0.6129739203400288\n",
      ">>>>> tuning fit_mlp with params {'alpha': [0.001, 0.01, 0.001], 'n_iter_no_change': [16, 8, -1], 'max_iter': [100, 400, 20]} <<<<<\n",
      "fit_mlp {'alpha': 0.01, 'n_iter_no_change': 8, 'max_iter': 400}: 0.6045875957905931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'alg': 'fit_mlp',\n",
       "  'res_params': {'alpha': 0.01, 'n_iter_no_change': 8, 'max_iter': 400},\n",
       "  'score': 0.6045875957905931},\n",
       " [{'alg': 'fit_elastic',\n",
       "   'res_params': {'alpha': 0.30000000000000004,\n",
       "    'l1_ratio': 1,\n",
       "    'max_iter': 3000},\n",
       "   'score': 0.4696670117932351},\n",
       "  {'alg': 'fit_tree',\n",
       "   'res_params': {'max_depth': 28,\n",
       "    'min_samples_split': 6,\n",
       "    'min_samples_leaf': 28},\n",
       "   'score': 0.6129739203400288},\n",
       "  {'alg': 'fit_mlp',\n",
       "   'res_params': {'alpha': 0.01, 'n_iter_no_change': 8, 'max_iter': 400},\n",
       "   'score': 0.6045875957905931}])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seoulbike = pd.read_csv('preprocessed_data/SeoulBikeData_processed.csv', index_col=0) # index_col=0 since there is an index column\n",
    "display(seoulbike)\n",
    "\n",
    "seoulbike_X = seoulbike.drop('Rented Bike Count', axis=1)\n",
    "seoulbike_y = seoulbike['Rented Bike Count']\n",
    "\n",
    "auto_ml(100, alg_list, seoulbike_X, seoulbike_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da9d4650-f2c3-46e7-9b08-186aed206dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notebook took this long in seconds: 1029.4496788978577\n"
     ]
    }
   ],
   "source": [
    "print(f'notebook took this long in seconds: {time.time()-notebook_time}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
