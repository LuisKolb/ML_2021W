{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn.preprocessing as prep\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisations\n",
    "\n",
    "def correlation(data):\n",
    "    corrMatrix = data.corr()\n",
    "    sn.heatmap(corrMatrix, annot=True)\n",
    "    plt.show()\n",
    "    return \n",
    "\n",
    "def scatterplot(data):\n",
    "    sn.set()\n",
    "    sn.pairplot(data[data.columns], size = 2.5)\n",
    "    plt.show();\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic Preprocessing\n",
    "\n",
    "def preprocessor(data, targetname, labelEncoding=True):\n",
    "    y = data.pop(targetname)\n",
    "    X = data     \n",
    "    \n",
    "    scaler = prep.RobustScaler().fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    \n",
    "        \n",
    "    if labelEncoding:\n",
    "        le = prep.LabelEncoder()\n",
    "        y = le.fit_transform(y)\n",
    "    \n",
    "    i = 1\n",
    "    SVD_components = X.shape[1]-i\n",
    "    svd = TruncatedSVD(n_components=SVD_components, random_state=42)\n",
    "    dataSVD = svd.fit_transform(X)\n",
    "    varianceExplained = np.sum(svd.explained_variance_)\n",
    "    maxVarianceExplained = varianceExplained\n",
    "    \n",
    "    while varianceExplained/maxVarianceExplained > .99 and X.shape[1]-i > 1:\n",
    "        SVD_components = X.shape[1]-i\n",
    "        svd = TruncatedSVD(n_components=SVD_components, random_state=42)\n",
    "        dataSVD = svd.fit_transform(X)\n",
    "        varianceExplained = np.sum(svd.explained_variance_)\n",
    "        i += 1\n",
    "        print(varianceExplained, SVD_components)\n",
    "    \n",
    "    \n",
    "    svd = TruncatedSVD(n_components=SVD_components+1, random_state=42)\n",
    "    dataSVD = svd.fit_transform(X)\n",
    "    \n",
    "    df_y = pd.DataFrame(y)\n",
    "    df_SVD = pd.DataFrame(dataSVD)\n",
    "    processedData = pd.concat([df_y, df_SVD], axis=1)\n",
    "\n",
    "    return processedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessorSeoul(data, targetname, labelEncoding=True, SVD_components=5):\n",
    "\n",
    "    def robustScaler(X, columnlabels):\n",
    "        \n",
    "        partialX = X[columnlabels]\n",
    "        scaler = prep.RobustScaler().fit(partialX)\n",
    "        scaledPartialX = pd.DataFrame(scaler.transform(partialX), columns=columnlabels)\n",
    "        \n",
    "        for item in range(len(columnlabels)):\n",
    "            X[columnlabels[item]] =  scaledPartialX[columnlabels[item]]\n",
    "\n",
    "        return X\n",
    "    \n",
    "    def ordinalScaler(X, columnlabels):\n",
    "        \n",
    "        partialX = X[columnlabels]\n",
    "        scaler = prep.RobustScaler().fit(partialX)\n",
    "        scaledPartialX = pd.DataFrame(scaler.transform(partialX), columns=columnlabels)\n",
    "        \n",
    "        for item in range(len(columnlabels)):\n",
    "            X[columnlabels[item]] =  scaledPartialX[columnlabels[item]]\n",
    "\n",
    "        return X\n",
    "    \n",
    "    def oneHotEnc(X, columnlabels):\n",
    "        \n",
    "        partialX = X[columnlabels]\n",
    "        encoder = prep.OneHotEncoder(sparse=False)\n",
    "        encoder.fit(partialX)\n",
    "        newFeatureNames = encoder.get_feature_names()\n",
    "        encodedPartialX = pd.DataFrame(encoder.transform(partialX), columns= newFeatureNames)\n",
    "        \n",
    "        for item in range(len(columnlabels)):\n",
    "            X = X.drop(columns=columnlabels[item])\n",
    "        \n",
    "        X = pd.concat([X, encodedPartialX], axis=1)\n",
    "\n",
    "        return X\n",
    "    \n",
    "    y = data.pop(targetname)\n",
    "    X = pd.DataFrame(data)\n",
    "    \n",
    "    X = robustScaler(X, ['Hour', 'Temperature(degC)', 'Humidity(%)',\n",
    "        'Wind speed (m/s)', 'Visibility (10m)', 'Dew point temperature(degC)',\n",
    "        'Solar Radiation (MJ/m2)', 'Rainfall(mm)', 'Snowfall (cm)', 'Wind speed (m/s)'])   \n",
    "    \n",
    "    \n",
    "    X = ordinalScaler(X, ['Date'])\n",
    "    X = oneHotEnc(X, ['Seasons'])\n",
    "    X = (X.replace({'Holiday': {'No Holiday': 0., 'Holiday': 1.}, \n",
    "                               'Functioning Day': {'No': 0., 'Yes': 1.}}))\n",
    "    \n",
    "    if labelEncoding:\n",
    "        le = prep.LabelEncoder()\n",
    "        y = le.fit_transform(y)\n",
    "    \n",
    "    i = 1\n",
    "    SVD_components = X.shape[1]-i\n",
    "    svd = TruncatedSVD(n_components=SVD_components, random_state=42)\n",
    "    dataSVD = svd.fit_transform(X)\n",
    "    varianceExplained = np.sum(svd.explained_variance_)\n",
    "    maxVarianceExplained = varianceExplained\n",
    "    \n",
    "    while varianceExplained/maxVarianceExplained > .99 and X.shape[1]-i > 1:\n",
    "        SVD_components = X.shape[1]-i\n",
    "        svd = TruncatedSVD(n_components=SVD_components, random_state=42)\n",
    "        dataSVD = svd.fit_transform(X)\n",
    "        varianceExplained = np.sum(svd.explained_variance_)\n",
    "        i += 1\n",
    "        print(varianceExplained, SVD_components)\n",
    "    \n",
    "    \n",
    "    svd = TruncatedSVD(n_components=SVD_components+1, random_state=42)\n",
    "    dataSVD = svd.fit_transform(X)\n",
    "    \n",
    "    df_y = pd.DataFrame(y)\n",
    "    df_SVD = pd.DataFrame(dataSVD) \n",
    "    processedData = pd.concat([df_y, df_SVD], axis=1)\n",
    "\n",
    "    return processedData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ********************************************\n",
    "# Breastcancer \n",
    "# ********************************************\n",
    "\n",
    "breastcancerRaw = pd.read_csv('breastcancer/breast-cancer-diagnostic.shuf.lrn.csv')\n",
    "breastcancerRaw.drop('ID', axis=1)\n",
    "breastcancerProcessed = preprocessor(breastcancerRaw, 'class')\n",
    "\n",
    "# correlation(pd.DataFrame(breastcancerProcessed))\n",
    "# scatterplot(pd.DataFrame(breastcancerProcessed.drop('class')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ********************************************\n",
    "# Concrete \n",
    "# ********************************************\n",
    "\n",
    "concreteRaw = pd.read_csv('concrete/concrete_data.csv')\n",
    "concreteProcessed = preprocessor(concreteRaw, 'Strength', False)\n",
    "\n",
    "# concrete.hist()\n",
    "# scatterplot(concrete)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ********************************************\n",
    "# Seoul Bike Sharing Demand \n",
    "# ********************************************\n",
    "\n",
    "seoulbike = pd.read_csv('seoulbike/SeoulBikeData.csv')\n",
    "\n",
    "dates = seoulbike['Date']\n",
    "\n",
    "for i in range(seoulbike.shape[0]):\n",
    "    dates[i] = time.mktime(datetime.datetime.strptime(str(dates[i]), \"%d/%m/%Y\").timetuple())   \n",
    "    \n",
    "seoulbike['Date'] = dates\n",
    "\n",
    "seoulbikeProcessed = preprocessorSeoul(seoulbike,'Rented Bike Count', False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
