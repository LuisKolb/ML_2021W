{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn.preprocessing as prep\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisations\n",
    "\n",
    "def correlation(data):\n",
    "    corrMatrix = data.corr()\n",
    "    sn.heatmap(corrMatrix, annot=True)\n",
    "    plt.show()\n",
    "    return \n",
    "\n",
    "def scatterplot(data):\n",
    "    sn.set()\n",
    "    sn.pairplot(data[data.columns], size = 2.5)s\n",
    "    plt.show();\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic Preprocessing\n",
    "\n",
    "def preprocessor(data, targetname, labelEncoding=True):\n",
    "    y = data.pop(targetname)\n",
    "    X = data     \n",
    "    \n",
    "    scaler = prep.RobustScaler().fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    \n",
    "        \n",
    "    if labelEncoding:\n",
    "        le = prep.LabelEncoder()\n",
    "        y = le.fit_transform(y)\n",
    "        df_y = pd.DataFrame(y, columns=['target'])\n",
    "    else:\n",
    "        df_y = y\n",
    "\n",
    "    \n",
    "    pca = PCA(.95)\n",
    "    data_PCA = pca.fit_transform(X)\n",
    "    \n",
    "    df_SVD = pd.DataFrame(data_PCA)\n",
    "    processedData = pd.concat([df_y, df_SVD], axis=1)\n",
    "    \n",
    "    # correlation(pd.concat([df_y, pd.DataFrame(data)], axis=1))\n",
    "\n",
    "    return processedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessorSeoul(data, targetname, labelEncoding=True):\n",
    "\n",
    "    def robustScaler(X, columnlabels):\n",
    "        \n",
    "        partialX = X[columnlabels]\n",
    "        scaler = prep.RobustScaler().fit(partialX)\n",
    "        scaledPartialX = pd.DataFrame(scaler.transform(partialX), columns=columnlabels)\n",
    "        \n",
    "        for item in range(len(columnlabels)):\n",
    "            X[columnlabels[item]] =  scaledPartialX[columnlabels[item]]\n",
    "\n",
    "        return X\n",
    "    \n",
    "    def ordinalScaler(X, columnlabels):\n",
    "        \n",
    "        partialX = X[columnlabels]\n",
    "        scaler = prep.RobustScaler().fit(partialX)\n",
    "        scaledPartialX = pd.DataFrame(scaler.transform(partialX), columns=columnlabels)\n",
    "        \n",
    "        for item in range(len(columnlabels)):\n",
    "            X[columnlabels[item]] =  scaledPartialX[columnlabels[item]]\n",
    "\n",
    "        return X\n",
    "    \n",
    "    def oneHotEnc(X, columnlabels):\n",
    "        \n",
    "        partialX = X[columnlabels]\n",
    "        encoder = prep.OneHotEncoder(sparse=False)\n",
    "        encoder.fit(partialX)\n",
    "        newFeatureNames = encoder.get_feature_names()\n",
    "        encodedPartialX = pd.DataFrame(encoder.transform(partialX), columns= newFeatureNames)\n",
    "        \n",
    "        for item in range(len(columnlabels)):\n",
    "            X = X.drop(columns=columnlabels[item])\n",
    "        \n",
    "        X = pd.concat([X, encodedPartialX], axis=1)\n",
    "\n",
    "        return X\n",
    "    \n",
    "    y = data.pop(targetname)\n",
    "    X = pd.DataFrame(data)\n",
    "    \n",
    "    X = robustScaler(X, ['Hour', 'Temperature(degC)', 'Humidity(%)',\n",
    "        'Wind speed (m/s)', 'Visibility (10m)', 'Dew point temperature(degC)',\n",
    "        'Solar Radiation (MJ/m2)', 'Rainfall(mm)', 'Snowfall (cm)', 'Wind speed (m/s)'])   \n",
    "    \n",
    "    \n",
    "    X = ordinalScaler(X, ['Date'])\n",
    "    X = oneHotEnc(X, ['Seasons'])\n",
    "    X = (X.replace({'Holiday': {'No Holiday': 0., 'Holiday': 1.}, \n",
    "                               'Functioning Day': {'No': 0., 'Yes': 1.}}))\n",
    "    \n",
    "    if labelEncoding:\n",
    "        le = prep.LabelEncoder()\n",
    "        y = le.fit_transform(y)\n",
    "        \n",
    "    pca = PCA(.9)\n",
    "    data_PCA = pca.fit_transform(X)\n",
    "\n",
    "    \n",
    "    df_y = pd.DataFrame(y)\n",
    "    df_SVD = pd.DataFrame(data_PCA) \n",
    "    processedData = pd.concat([df_y, df_SVD], axis=1)\n",
    "\n",
    "    return processedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dateConversion():\n",
    "    dates = seoulbike['Date']\n",
    "    \n",
    "    for i in range(seoulbike.shape[0]):\n",
    "        dates[i] = time.mktime(datetime.datetime.strptime(str(dates[i]), \"%d/%m/%Y\").timetuple())   \n",
    "        \n",
    "    seoulbike['Date'] = dates\n",
    "    seoulbike.to_csv('seoulbike/SeoulBikeData_dateconv.csv')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ********************************************\n",
    "# Breastcancer \n",
    "# ********************************************\n",
    "\n",
    "breastcancerRaw = pd.read_csv('breastcancer/breast-cancer-diagnostic.shuf.lrn.csv')\n",
    "breastcancerRaw = breastcancerRaw.drop('ID', axis=1)\n",
    "breastcancerProcessed = preprocessor(breastcancerRaw, 'class')\n",
    "\n",
    "# breastcancerProcessed.to_csv('preprocessed/breast-cancer-diagnostic.shuf.lrn_processed.csv')\n",
    "correlation(pd.DataFrame(breastcancerProcessed))\n",
    "scatterplot(pd.DataFrame(breastcancerProcessed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ********************************************\n",
    "# Concrete \n",
    "# ********************************************\n",
    "\n",
    "concreteRaw = pd.read_csv('concrete/concrete_data.csv')\n",
    "concreteProcessed = preprocessor(concreteRaw, 'Strength', False)\n",
    "concreteProcessed.to_csv('preprocessed/concrete_data_processed.csv')\n",
    "correlation(concreteProcessed)\n",
    "scatterplot(concreteProcessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ********************************************\n",
    "# Seoul Bike Sharing Demand \n",
    "# ********************************************\n",
    "\n",
    "# seoulbike = pd.read_csv('seoulbike/SeoulBikeData.csv')\n",
    "# dateConversion()\n",
    "\n",
    "seoulbike = pd.read_csv('seoulbike/SeoulBikeData_dateconv.csv')\n",
    "seoulbikeProcessed = preprocessorSeoul(seoulbike,'Rented Bike Count', False)\n",
    "\n",
    "correlation(pd.DataFrame(seoulbikeProcessed))\n",
    "# scatterplot(pd.DataFrame(seoulbikeProcessed))\n",
    "\n",
    "seoulbikeProcessed.to_csv('preprocessed/SeoulBikeData_processed.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
